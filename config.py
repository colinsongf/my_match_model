
import argparse

parser = argparse.ArgumentParser('QA dataset')

parser.add_argument('--prepare',action = 'store_true',help = 'prepare my dataset')
parser.add_argument('--train',action = 'store_true',help = 'train my model')
parser.add_argument('--evaluate',action ='store_true', help = 'evaluate my dev sets')
parser.add_argument('--predict',action = 'store_true',help = 'predict the answers for test')
parser.add_argument('--gpu',type = str,default = '0',help = 'specify gpu device')
train_settings = parser.add_argument_group('train_setting')
train_settings.add_argument('--embedding_size',type= int,default = 100,help = 'embedding_dim')
train_settings.add_argument('--filter_sizes',default = [2,3,4,5],help = "Comma-separated filter sizes")
train_settings.add_argument('--num_filters',type = int,default = 128,help = 'number of filters')
train_settings.add_argument('--dropout_keep_prob',type = float,default = 0.5,help = 'dropout keep probability')
train_settings.add_argument('--l2_reg_lambda',type = float,default = 0.0001,help = 'L2 regularizaion lambda (default: 0.0)')
train_settings.add_argument('--learning_rate',type = float,default = 0.0001,help = 'learn rate')
train_settings.add_argument('--pooling',type = str,default = 'max',help = 'pooling strategy')
train_settings.add_argument('--clean',type = bool,default = False,help = 'clean or not')
train_settings.add_argument('--epochs',type = int,default = 500)
train_settings.add_argument('--num_epochs',type = int,default = 10,help = 'Number of training epochs (default: 200)')
train_settings.add_argument('--batch_size',type = int,default = 64,help = 'batch size')
train_settings.add_argument('--optim',default = 'adam',help = 'optimizer type')
train_settings.add_argument('--char_alphabet_size',default = 70,help = 'char_alphabet_size')
train_settings.add_argument('--char_filter_size',default = [4,5],help = 'char_filter')
train_settings.add_argument('--char_embed_size',default = 70,help = 'char_embed_size')
train_settings.add_argument('--char_num_filters',default = 128,help = 'char_num_filters')
train_settings.add_argument('--char_length',type = int,default = 500,help = 'char sentenc lenth')
train_settings.add_argument('--input',default = 'word',help = 'input layer')
train_settings.add_argument('--num_classes',type = int,default = 2,help = 'Number of classes')
model_settings = parser.add_argument_group('model_setting')
model_settings.add_argument('--max_input_left',type = int,default = 40,help = 'max_len_left')
model_settings.add_argument('--max_input_right',type = int,default = 40,help = 'max_len_right')
model_settings.add_argument('--trainable',type = bool,default = False,help = 'is embedding trainable? (default: False)')
model_settings.add_argument('--evaluate_every',type = int,default = 500,help = 'batch Evaluate model on dev set after this many steps')
model_settings.add_argument('--checkpoint_every',type = int,default = 500,help = 'checkpoing_every step')


path_settings = parser.add_argument_group('path setting')
path_settings.add_argument('--train_files',nargs = '+',default = 'data/tencent/train.txt')
path_settings.add_argument('--test_files',nargs = '+',default = 'data/tencent/test.txt')
path_settings.add_argument('--dev_files',nargs = '+',default = 'data/tencent/dev.txt')
path_settings.add_argument('--embedding_file',default = 'embedding/wiki.ch.text100.vector')
path_settings.add_argument('--vocab_dir',default = 'data/vocab/',help = 'the dir to save the vocab')
path_settings.add_argument('--model_dir',default = 'data/models/',help = 'the dir to store models')
path_settings.add_argument('--summary_dir',default = 'data/summary',help = 'the dir to write tensorboard summary')
path_settings.add_argument('--log_path',help = 'path of the log file, if not set,logs are printed  to console')
path_settings.add_argument('--result_dir',default = 'data/resuts',help = 'the dir to output')
# path_settings.add_argument('--inpath',help = 'predict input path')
path_settings.add_argument('--outpath',help = 'outpath')
args = parser.parse_args()


